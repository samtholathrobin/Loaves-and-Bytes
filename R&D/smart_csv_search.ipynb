{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cd0bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41b17165",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_df = pd.read_csv(\"Menus/menu1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7738463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=f\"{row['name']}. {row['description']}. Category: {row['category']}.\",\n",
    "        metadata={\n",
    "            \"id\": row[\"id\"],\n",
    "            \"description\": row[\"description\"],\n",
    "            \"name\": row[\"name\"],\n",
    "            \"price\": row[\"price\"],\n",
    "            \"category\": row[\"category\"],\n",
    "            \"tags\": row[\"tags\"]\n",
    "        }\n",
    "    )\n",
    "    for _, row in menu_df.iterrows()\n",
    "]\n",
    "\n",
    "embedding_model_nomic = OllamaEmbeddings(model = 'nomic-embed-text')\n",
    "menu_vector_store = FAISS.from_documents(documents, embedding_model_nomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9205fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_filter(\n",
    "    query: str,\n",
    "    vector_store: FAISS,\n",
    "    embedding_model: OllamaEmbeddings,\n",
    "    threshold: float = 0.75,\n",
    "    k: int = 10\n",
    "    ) -> List[Document]:\n",
    "\n",
    "    \"\"\"\n",
    "    Perform a semantic search and filter by similarity threshold.\n",
    "\n",
    "    Returns a list of tuples: (menu item name, similarity score, page content).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Embed query\n",
    "    query_vector = embedding_model.embed_query(query)\n",
    "\n",
    "    # Step 2: Search using FAISS\n",
    "    D, I = vector_store.index.search(np.array([query_vector]), k=k)\n",
    "    similarities = 1 - D[0]  # Convert distance to similarity\n",
    "\n",
    "    # Step 3: Filter results above threshold\n",
    "    results = []\n",
    "    for i, sim in zip(I[0], similarities):\n",
    "        if sim >= threshold:\n",
    "            doc_id = vector_store.index_to_docstore_id[i]\n",
    "            doc = vector_store.docstore._dict[doc_id]\n",
    "            results.append(doc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "697e4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_menu(user_query, category_filter=None, tags_filter=None):\n",
    "\n",
    "    # Semantic similarity search\n",
    "    if user_query:\n",
    "        results = semantic_filter(\n",
    "            query=user_query,\n",
    "            vector_store=menu_vector_store,\n",
    "            embedding_model=embedding_model_nomic,\n",
    "            threshold=0.1,\n",
    "            k=10\n",
    "        )\n",
    "    else:\n",
    "    # If no query, return all documents\n",
    "        results = list(menu_vector_store.docstore._dict.values())\n",
    "\n",
    "\n",
    "    if category_filter:\n",
    "        results = [doc for doc in results if doc.metadata[\"category\"].lower() == category_filter.lower()]\n",
    "\n",
    "    if tags_filter:\n",
    "        results = [doc for doc in results if tags_filter.lower() in [tag.lower() for tag in doc.metadata[\"tags\"].split(\",\")]]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "07cf057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grace Garden Salad\t6.5\n",
      "Mixed greens with vinaigrette dressing and croutons\n",
      "\n",
      "Daily Bread Basket\t4.99\n",
      "Assorted artisan breads with olive oil and balsamic\n",
      "\n",
      "Saviorâ€™s Samosas\t5.99\n",
      "Golden pastry filled with spiced potatoes and peas\n",
      "\n",
      "Sanctified Spring Rolls\t6.0\n",
      "Rice paper rolls with tofu, mint, and vermicelli\n",
      "\n",
      "Samosa Chaat\t6.99\n",
      "Crushed samosas topped with yogurt, chutneys, and spices\n",
      "\n",
      "Spring Rolls\t5.75\n",
      "Crispy rolls filled with vegetables and noodles\n",
      "\n",
      "Gobi Manchurian\t7.5\n",
      "Crispy cauliflower tossed in tangy Indo-Chinese sauce\n",
      "\n",
      "Vegetable Momos\t6.5\n",
      "Steamed dumplings filled with mixed vegetables\n",
      "\n",
      "Hot and Sour Soup\t4.99\n",
      "Spicy and tangy Chinese-style soup\n",
      "\n",
      "Fried Wontons\t5.25\n",
      "Deep-fried wontons filled with veggies or meat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = search_menu(user_query =None, category_filter=\"Appetizer\", tags_filter=None)  # Example usage\n",
    "for i in [r.metadata['name']+'\\t'+str(r.metadata['price'])+'\\n'+r.metadata['description']+'\\n' for r in response]:  # Print names of the filtered results\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d312a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "menu-maker-500",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
